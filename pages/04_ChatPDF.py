import streamlit as st
from openai import OpenAI

st.title("ChatPDF: ì—…ë¡œë“œí•œ PDFì™€ ëŒ€í™”í•˜ê¸°")

# 1) ë©”ì¸ í˜ì´ì§€ì—ì„œ API Key ê°€ì ¸ì˜¤ê¸° --------------------------------
if "api_key" not in st.session_state or not st.session_state.api_key:
    st.warning("âš  ë¨¼ì € ë©”ì¸ í˜ì´ì§€ì—ì„œ OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=st.session_state.api_key)

# 2) ChatPDFìš© ìƒíƒœ ë³€ìˆ˜ë“¤ -------------------------------------------
if "chatpdf_vector_store_id" not in st.session_state:
    st.session_state.chatpdf_vector_store_id = None

if "chatpdf_history" not in st.session_state:
    st.session_state.chatpdf_history = []  # ì±„íŒ… ë¡œê·¸


# 3) ìƒë‹¨ ì˜ì—­: PDF ì—…ë¡œë“œ + Clear ë²„íŠ¼ -------------------------------
col1, col2 = st.columns([3, 1])

with col1:
    uploaded_pdf = st.file_uploader(
        "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (í•œ ê°œë§Œ)",
        type=["pdf"],
        accept_multiple_files=False,
    )

with col2:
    # Vector store ë° ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”
    if st.button("ğŸ§¹ Clear", help="Vector storeì™€ ëŒ€í™” ë‚´ìš©ì„ ëª¨ë‘ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."):
        # ê¸°ì¡´ vector store ì‚­ì œ
        if st.session_state.chatpdf_vector_store_id:
            try:
                client.vector_stores.delete(st.session_state.chatpdf_vector_store_id)
            except Exception:
                # ì´ë¯¸ ì‚­ì œë˜ì—ˆê±°ë‚˜ ì—†ëŠ” ê²½ìš°ëŠ” ë¬´ì‹œ
                pass
        st.session_state.chatpdf_vector_store_id = None
        st.session_state.chatpdf_history = []
        st.success("Vector storeì™€ ì±„íŒ… ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")


# 4) PDFë¥¼ Vector Storeì— ì˜¬ë¦¬ê¸° ------------------------------------
if uploaded_pdf is not None and st.session_state.chatpdf_vector_store_id is None:
    # ì•„ì§ vector storeê°€ ì—†ê³ , PDFê°€ ìƒˆë¡œ ì—…ë¡œë“œëœ ê²½ìš°
    with st.spinner("PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ì¸ë±ì‹± ì¤‘ì…ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)"):
        # vector store ìƒì„±
        vector_store = client.vector_stores.create(name="chatpdf-store")

        # ì—…ë¡œë“œí•œ pdf íŒŒì¼ì„ vector storeì— ì¶”ê°€ (upload_and_poll ì‚¬ìš©)
        file_batch = client.vector_stores.file_batches.upload_and_poll(
            vector_store_id=vector_store.id,
            files=[uploaded_pdf],  # streamlit UploadedFile ê°ì²´ ê·¸ëŒ€ë¡œ ì „ë‹¬
        )

        st.session_state.chatpdf_vector_store_id = vector_store.id

    st.success("PDF ì—…ë¡œë“œ ë° ì¸ë±ì‹±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

# 5) ëŒ€í™” UI ---------------------------------------------------------
vs_id = st.session_state.chatpdf_vector_store_id

if vs_id is None:
    st.info("ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´, ê·¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

st.write("ì´ì œ ì—…ë¡œë“œí•œ PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ ë³´ì„¸ìš”!")

# ì´ì „ ì±„íŒ… ë¡œê·¸ ì¶œë ¥
for msg in st.session_state.chatpdf_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ìƒˆ ì§ˆë¬¸ ì…ë ¥
user_msg = st.chat_input("PDFì™€ ê´€ë ¨í•´ ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”")

if user_msg:
    # (1) user ë©”ì‹œì§€ í™”ë©´ + íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    st.session_state.chatpdf_history.append({"role": "user", "content": user_msg})
    with st.chat_message("user"):
        st.markdown(user_msg)

    # (2) Responses API + File Search í˜¸ì¶œ -------------------------
    with st.chat_message("assistant"):
        with st.spinner("PDF ë‚´ìš©ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            response = client.responses.create(
                model="gpt-5-mini",
                input=[
                    {
                        "role": "system",
                        "content": (
                            "ë„ˆëŠ” ì—…ë¡œë“œëœ PDF íŒŒì¼ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œë§Œ "
                            "ì„±ì‹¤í•˜ê²Œ ë‹µë³€í•˜ëŠ” ì¡°êµì•¼. PDF ë‚´ìš©ê³¼ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” "
                            "'PDF ë‚´ìš©ê³¼ ì§ì ‘ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•´ ì£¼ì„¸ìš”.'ë¼ê³  ë‹µí•´."
                        ),
                    },
                    *[
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state.chatpdf_history
                    ],
                ],
                tools=[
                    {
                        "type": "file_search",
                        "vector_store_ids": [vs_id],
                        "max_num_results": 10,
                    }
                ],
                include=["file_search_call.results"],  # ì„ íƒì‚¬í•­: ê²€ìƒ‰ ê²°ê³¼ë„ ì‘ë‹µì— í¬í•¨
            )

            answer = response.output_text
            st.markdown(answer)

    # (3) assistant ë‹µë³€ ì €ì¥
    st.session_state.chatpdf_history.append(
        {"role": "assistant", "content": answer}
    )
